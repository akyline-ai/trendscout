# backend/app/api/trends.py
import time
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import or_, delete # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è
from typing import List, Optional
from pydantic import BaseModel, Field

from ..core.database import get_db
from ..db.models import Trend
from ..services.collector import TikTokCollector
from ..services.scorer import TrendScorer
from ..services.ml_client import get_ml_client
from ..services.clustering import cluster_trends_by_visuals 

# –ò–ú–ü–û–†–¢ –ü–õ–ê–ù–ò–†–û–í–©–ò–ö–ê
from ..services.scheduler import scheduler, rescan_videos_task

router = APIRouter()

class SearchRequest(BaseModel):
    target: Optional[str] = None         # –û—Å–Ω–æ–≤–Ω–æ–π –≤–≤–æ–¥ (–∫–ª—é—á –∏–ª–∏ @username)
    keywords: Optional[List[str]] = []   # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    mode: str = "keywords"               # "keywords" –∏–ª–∏ "username"
    business_desc: Optional[str] = ""
    is_deep: Optional[bool] = False
    time_window: Optional[str] = None
    rescan_hours: int = Field(default=24, ge=1)

def trend_to_dict(trend: Trend) -> dict:
    return {
        "id": trend.id,
        "platform_id": trend.platform_id,
        "url": trend.url,
        "cover_url": trend.cover_url,
        "description": trend.description,
        "author_username": trend.author_username,
        "stats": trend.stats,
        "initial_stats": trend.initial_stats, 
        "uts_score": trend.uts_score,
        "cluster_id": trend.cluster_id,       
        "music_id": trend.music_id,
        "music_title": trend.music_title,
        "last_scanned_at": trend.last_scanned_at
    }

# --- ‚úÖ –≠–ù–î–ü–û–ò–ù–¢ ¬´–ü–†–û–ß–ò–¢–ê–õ –ò –£–î–ê–õ–ò–õ¬ª ---
@router.get("/results")
def get_saved_results(keyword: str, mode: str = "keywords", db: Session = Depends(get_db)):
    """
    –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. 
    –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø—Ä–æ—à–ª–∏ —Ä–µ—Å–∫–∞–Ω (–¢–æ—á–∫–∞ –ë), –æ–Ω–∏ —É–¥–∞–ª—è—é—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–¥–∞—á–∏.
    """
    print(f"üìÇ DB Buffer Read: –∏—â–µ–º '{keyword}' –≤ —Ä–µ–∂–∏–º–µ '{mode}'")
    clean_nick = keyword.lower().strip().replace("@", "")
    
    if mode == "username":
        # –°–¢–†–û–ì–û: –∏—â–µ–º –≤–∏–¥–µ–æ, –≥–¥–µ —ç—Ç–æ—Ç —é–∑–µ—Ä —è–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–æ–º
        query = db.query(Trend).filter(Trend.author_username.ilike(clean_nick))
    else:
        # –û–ë–´–ß–ù–´–ô –ü–û–ò–°–ö: –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
        search_term = f"%{keyword}%"
        query = db.query(Trend).filter(
            or_(Trend.description.ilike(search_term), Trend.vertical.ilike(search_term))
        )
    
    results = query.order_by(Trend.uts_score.desc()).all()
    data_to_return = [trend_to_dict(t) for t in results]

    # ‚úÖ –°–ê–ú–û–û–ß–ò–°–¢–ö–ê: –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ —Å–≤–µ—Ä–∫–∞ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–µ—Å—Ç—å –¥–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∫–∞–Ω–∞)
    ids_to_clean = [t.id for t in results if t.last_scanned_at is not None]
    
    if ids_to_clean:
        db.execute(delete(Trend).where(Trend.id.in_(ids_to_clean)))
        db.commit()
        print(f"üßπ –ë–î –û—á–∏—â–µ–Ω–∞: –£–¥–∞–ª–µ–Ω–æ {len(ids_to_clean)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –≤—ã–¥–∞—á–∏.")

    return {"status": "ok", "items": data_to_return}

@router.post("/search")
def search_trends(req: SearchRequest, db: Session = Depends(get_db)):
    """Deep Scan + Auto Rescan Scheduler (Point A Setup)"""
    search_targets = [req.target] if req.target else req.keywords
    if not search_targets or not search_targets[0]:
        return {"status": "error", "message": "No query provided"}

    print(f"üîé API Search [{req.mode}]: {search_targets} (Deep: {req.is_deep})")
    
    collector = TikTokCollector()
    raw_items = []
    clean_items = []
    
    # 1. –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–Ω–µ deep) - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if not req.is_deep and req.mode != "username":
        limit = 20
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        clean_nick = search_targets[0].lower().strip().replace("@", "")
        search_term = f"%{clean_nick}%"
        cached_results = db.query(Trend).filter(
            or_(Trend.description.ilike(search_term), Trend.vertical.ilike(search_term))
        ).order_by(Trend.uts_score.desc()).limit(limit).all()
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–≤–µ–∂–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        if cached_results:
            recent_cached = [t for t in cached_results 
                           if not t.last_scanned_at or 
                           (datetime.utcnow() - t.last_scanned_at) < timedelta(hours=1)]
            if recent_cached:
                print(f"üíæ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ({len(recent_cached)} –∑–∞–ø–∏—Å–µ–π) - –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º Apify")
                return {"status": "ok", "items": [trend_to_dict(t) for t in recent_cached]}
        
        # –ö—ç—à–∞ –Ω–µ—Ç - –∑–∞–ø—É—Å–∫–∞–µ–º Apify
        print(f"üîÑ –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º Apify –¥–ª—è –ø–æ–∏—Å–∫–∞ '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="search", is_deep=False)
        
        if not raw_items:
            return {"status": "empty", "items": []}
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for item in raw_items:
            v_count = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
            if v_count >= 5000: clean_items.append(item)
    
    # 2. –î–ª—è username –∏–ª–∏ deep scan - –≤—Å–µ–≥–¥–∞ –ø–∞—Ä—Å–∏–º
    elif req.mode == "username":
        limit = 20
        print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="profile", is_deep=True)
        if not raw_items:
            return {"status": "empty", "items": []}
        clean_items = raw_items  # –î–ª—è —é–∑–µ—Ä–∞ –±–µ—Ä–µ–º –≤—Å—ë –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    
    elif req.is_deep:
        limit = 50
        print(f"üî¨ Deep Scan –¥–ª—è '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="search", is_deep=req.is_deep)
        if not raw_items:
            return {"status": "empty", "items": []}
        # –î–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ
        for item in raw_items:
            v_count = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
            if v_count >= 5000: clean_items.append(item)

    # --- ‚úÖ –†–ï–ñ–ò–ú 1: –¢–†–ï–ù–î–´ (–û–ë–´–ß–ù–´–ô –ü–û–ò–°–ö –ë–ï–ó DEEP SCAN) ---
    if not req.is_deep:
        # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
        live_results = []
        for item in clean_items:
            v_meta = item.get("video") or item.get("videoMeta") or {}
            live_results.append({
                "url": item.get("postPage") or item.get("url") or item.get("webVideoUrl"),
                "cover_url": (v_meta.get("coverUrl") or item.get("coverUrl") or "").replace(".heic", ".jpeg"),
                "description": item.get("title") or item.get("desc") or "No desc",
                "author_username": (item.get("channel") or item.get("authorMeta") or {}).get("username") or "unknown",
                "stats": {"playCount": int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)},
                "uts_score": 0
            })
        return {"status": "ok", "items": live_results}

    # --- ‚úÖ –†–ï–ñ–ò–ú 2: DEEP SCAN (–ò–°–ü–û–õ–¨–ó–£–ï–ú –í–†–ï–ú–ï–ù–ù–´–ô –ë–£–§–ï–† –ë–î) ---
    scorer = TrendScorer()
    processed_trends_objects = [] 
    cascade_total = len(clean_items)

    for item in clean_items:
        p_id = str(item.get("id"))
        video_url = item.get("postPage") or item.get("url") or item.get("webVideoUrl")
        views_now = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
        current_stats = {"playCount": views_now}

        existing_video = db.query(Trend).filter(or_(Trend.platform_id == p_id, Trend.url == video_url)).first()

        try:
            if existing_video:
                # ‚úÖ –°–±—Ä–æ—Å –¢–æ—á–∫–∏ –ê –ø—Ä–∏ –Ω–æ–≤–æ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ (—Ö—Ä–∞–Ω–∏–º –≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è —Å–≤–µ—Ä–∫–∏)
                existing_video.initial_stats = current_stats 
                existing_video.stats = current_stats
                existing_video.last_scanned_at = None # –û–±–Ω—É–ª—è–µ–º, —á—Ç–æ–±—ã —Ä–µ—Å–∫–∞–Ω –ø–æ—Å—Ç–∞–≤–∏–ª –Ω–æ–≤—É—é –º–µ—Ç–∫—É
                db.add(existing_video)
                processed_trends_objects.append(existing_video)
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å ¬´–±—É—Ñ–µ—Ä–∞¬ª
                new_trend = Trend(
                    platform_id=p_id, url=video_url, 
                    cover_url=(item.get("video", {}).get("coverUrl") or "").replace(".heic", ".jpeg"),
                    description=item.get("title") or "No desc",
                    stats=current_stats, initial_stats=current_stats,
                    author_username=(item.get("channel") or {}).get("username") or "unknown",
                    uts_score=0, vertical=search_targets[0] or "deep_scan",
                    last_scanned_at=None
                )
                db.add(new_trend)
                processed_trends_objects.append(new_trend)
            db.commit()
        except: db.rollback()

    # 3. –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø (–¢–æ–ª—å–∫–æ –¥–ª—è Deep Scan)
    if req.is_deep and processed_trends_objects:
        processed_trends_objects = cluster_trends_by_visuals(processed_trends_objects)
        for t in processed_trends_objects: db.add(t)
        try: db.commit()
        except: db.rollback()

    # 4. –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –°–í–ï–†–ö–ò (2 –ú–ò–ù–£–¢–´ –¢–ï–°–¢)
    if req.is_deep and processed_trends_objects:
        saved_urls = [t.url for t in processed_trends_objects if t.url]
        if saved_urls:
            run_date = datetime.now() + timedelta(minutes=2) 
            scheduler.add_job(
                rescan_videos_task, 'date', run_date=run_date, 
                args=[saved_urls, f"batch_{int(time.time())}"]
            )
            print(f"‚è±Ô∏è –ó–ê–î–ê–ß–ê –°–í–ï–†–ö–ò –û–¢–ü–†–ê–í–õ–ï–ù–ê: –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 2 –º–∏–Ω—É—Ç—ã.")

    return {"status": "ok", "items": [trend_to_dict(t) for t in processed_trends_objects]}