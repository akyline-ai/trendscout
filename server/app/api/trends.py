# backend/app/api/trends.py
import time
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import or_, delete # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è
from typing import List, Optional
from pydantic import BaseModel, Field

from ..core.database import get_db
from ..db.models import Trend
from ..services.collector import TikTokCollector
from ..services.scorer import TrendScorer
from ..services.ml_client import get_ml_client
from ..services.clustering import cluster_trends_by_visuals 

# –ò–ú–ü–û–†–¢ –ü–õ–ê–ù–ò–†–û–í–©–ò–ö–ê
from ..services.scheduler import scheduler, rescan_videos_task

router = APIRouter()

class SearchRequest(BaseModel):
    target: Optional[str] = None         # –û—Å–Ω–æ–≤–Ω–æ–π –≤–≤–æ–¥ (–∫–ª—é—á –∏–ª–∏ @username)
    keywords: Optional[List[str]] = []   # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    mode: str = "keywords"               # "keywords" –∏–ª–∏ "username"
    business_desc: Optional[str] = ""
    is_deep: Optional[bool] = False
    time_window: Optional[str] = None
    rescan_hours: int = Field(default=24, ge=1)

def trend_to_dict(trend: Trend) -> dict:
    return {
        "id": trend.id,
        "platform_id": trend.platform_id,
        "url": trend.url,
        "cover_url": trend.cover_url,
        "description": trend.description,
        "author_username": trend.author_username,
        "stats": trend.stats,
        "initial_stats": trend.initial_stats, 
        "uts_score": trend.uts_score,
        "cluster_id": trend.cluster_id,       
        "music_id": trend.music_id,
        "music_title": trend.music_title,
        "last_scanned_at": trend.last_scanned_at
    }

# --- ‚úÖ –≠–ù–î–ü–û–ò–ù–¢ ¬´–ü–†–û–ß–ò–¢–ê–õ –ò –£–î–ê–õ–ò–õ¬ª ---
@router.get("/results")
def get_saved_results(keyword: str, mode: str = "keywords", db: Session = Depends(get_db)):
    """
    –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. 
    –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø—Ä–æ—à–ª–∏ —Ä–µ—Å–∫–∞–Ω (–¢–æ—á–∫–∞ –ë), –æ–Ω–∏ —É–¥–∞–ª—è—é—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–¥–∞—á–∏.
    """
    print(f"üìÇ DB Buffer Read: –∏—â–µ–º '{keyword}' –≤ —Ä–µ–∂–∏–º–µ '{mode}'")
    clean_nick = keyword.lower().strip().replace("@", "")
    
    if mode == "username":
        # –°–¢–†–û–ì–û: –∏—â–µ–º –≤–∏–¥–µ–æ, –≥–¥–µ —ç—Ç–æ—Ç —é–∑–µ—Ä —è–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–æ–º
        query = db.query(Trend).filter(Trend.author_username.ilike(clean_nick))
    else:
        # –û–ë–´–ß–ù–´–ô –ü–û–ò–°–ö: –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
        search_term = f"%{keyword}%"
        query = db.query(Trend).filter(
            or_(Trend.description.ilike(search_term), Trend.vertical.ilike(search_term))
        )
    
    results = query.order_by(Trend.uts_score.desc()).all()
    data_to_return = [trend_to_dict(t) for t in results]

    # ‚úÖ –°–ê–ú–û–û–ß–ò–°–¢–ö–ê: –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ —Å–≤–µ—Ä–∫–∞ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–µ—Å—Ç—å –¥–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∫–∞–Ω–∞)
    ids_to_clean = [t.id for t in results if t.last_scanned_at is not None]
    
    if ids_to_clean:
        db.execute(delete(Trend).where(Trend.id.in_(ids_to_clean)))
        db.commit()
        print(f"üßπ –ë–î –û—á–∏—â–µ–Ω–∞: –£–¥–∞–ª–µ–Ω–æ {len(ids_to_clean)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –≤—ã–¥–∞—á–∏.")

    return {"status": "ok", "items": data_to_return}

@router.post("/search")
def search_trends(req: SearchRequest, db: Session = Depends(get_db)):
    """Deep Scan + Auto Rescan Scheduler (Point A Setup)"""
    try:
        search_targets = [req.target] if req.target else req.keywords
        if not search_targets or not search_targets[0]:
            return {"status": "error", "message": "No query provided"}
    except Exception as e:
        print(f"‚ùå Error parsing request: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid request: {str(e)}")

    print(f"üîé API Search [{req.mode}]: {search_targets} (Deep: {req.is_deep})")
    
    collector = TikTokCollector()
    raw_items = []
    clean_items = []
    
    # 1. –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–Ω–µ deep) - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if not req.is_deep and req.mode != "username":
        limit = 20
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
            clean_nick = search_targets[0].lower().strip().replace("@", "")
            search_term = f"%{clean_nick}%"
            cached_results = db.query(Trend).filter(
                or_(Trend.description.ilike(search_term), Trend.vertical.ilike(search_term))
            ).order_by(Trend.uts_score.desc()).limit(limit).all()
        except Exception as e:
            print(f"‚ùå Error querying database cache: {e}")
            cached_results = []
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–≤–µ–∂–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        if cached_results:
            recent_cached = [t for t in cached_results 
                           if not t.last_scanned_at or 
                           (datetime.utcnow() - t.last_scanned_at) < timedelta(hours=1)]
            if recent_cached:
                print(f"üíæ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ({len(recent_cached)} –∑–∞–ø–∏—Å–µ–π) - –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º Apify")
                return {"status": "ok", "items": [trend_to_dict(t) for t in recent_cached]}
        
        # –ö—ç—à–∞ –Ω–µ—Ç - –∑–∞–ø—É—Å–∫–∞–µ–º Apify
        print(f"üîÑ –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º Apify –¥–ª—è –ø–æ–∏—Å–∫–∞ '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="search", is_deep=False)
        
        if not raw_items:
            return {"status": "empty", "items": []}
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for item in raw_items:
            v_count = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
            if v_count >= 5000: clean_items.append(item)
    
    # 2. –î–ª—è username –∏–ª–∏ deep scan - –≤—Å–µ–≥–¥–∞ –ø–∞—Ä—Å–∏–º
    elif req.mode == "username":
        limit = 20
        print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="profile", is_deep=True)
        if not raw_items:
            return {"status": "empty", "items": []}
        clean_items = raw_items  # –î–ª—è —é–∑–µ—Ä–∞ –±–µ—Ä–µ–º –≤—Å—ë –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    
    elif req.is_deep:
        limit = 50
        print(f"üî¨ Deep Scan –¥–ª—è '{search_targets[0]}'...")
        raw_items = collector.collect(search_targets, limit=limit, mode="search", is_deep=req.is_deep)
        if not raw_items:
            return {"status": "empty", "items": []}
        # –î–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ
        for item in raw_items:
            v_count = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
            if v_count >= 5000: clean_items.append(item)

    # --- ‚úÖ –†–ï–ñ–ò–ú 1: –¢–†–ï–ù–î–´ (–û–ë–´–ß–ù–´–ô –ü–û–ò–°–ö –ë–ï–ó DEEP SCAN) ---
    if not req.is_deep:
        # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
        live_results = []
        for idx, item in enumerate(clean_items):
            # Debug: print first item structure
            if idx == 0:
                print(f"üîç DEBUG: First item keys: {list(item.keys())}")
                print(f"üîç DEBUG: play_addr sources: v_meta.playAddr={bool((item.get('video') or {}).get('playAddr'))}, item.playAddr={bool(item.get('playAddr'))}")
                print(f"üîç DEBUG: URL: {item.get('webVideoUrl') or item.get('postPage') or item.get('url')}")

            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –æ—Ç Apify
            v_meta = item.get("video") or item.get("videoMeta") or {}
            author_meta = item.get("author") or item.get("authorMeta") or item.get("channel") or {}
            stats = item.get("stats") or {}

            # Cover URL –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
            cover_url = (
                v_meta.get("cover") or
                v_meta.get("coverUrl") or
                v_meta.get("dynamicCover") or
                item.get("coverUrl") or
                item.get("cover") or
                item.get("videoCover") or
                ""
            ).replace(".heic", ".jpeg").replace(".webp", ".jpeg")

            # URL –≤–∏–¥–µ–æ
            video_url = (
                item.get("webVideoUrl") or
                item.get("postPage") or
                item.get("url") or
                item.get("videoUrl") or
                f"https://www.tiktok.com/@{author_meta.get('uniqueId', 'user')}/video/{item.get('id', '')}"
            )

            # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ —Ñ–∞–π–ª –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            play_addr = (
                v_meta.get("playAddr") or
                v_meta.get("downloadAddr") or
                item.get("videoUrl") or
                item.get("playAddr") or
                ""
            )

            # –û–ø–∏—Å–∞–Ω–∏–µ
            description = (
                item.get("text") or
                item.get("desc") or
                item.get("title") or
                item.get("description") or
                "No description"
            )

            # Username
            username = (
                author_meta.get("uniqueId") or
                author_meta.get("username") or
                item.get("authorName") or
                "unknown"
            )

            # Stats
            play_count = (
                stats.get("playCount") or
                stats.get("views") or
                item.get("views") or
                item.get("playCount") or
                0
            )

            digg_count = stats.get("diggCount") or stats.get("likes") or item.get("likes") or 0
            comment_count = stats.get("commentCount") or stats.get("comments") or item.get("comments") or 0
            share_count = stats.get("shareCount") or stats.get("shares") or item.get("shares") or 0

            # Hashtags
            hashtags = item.get("hashtags") or item.get("challenges") or []
            hashtags_list = []
            if isinstance(hashtags, list):
                for tag in hashtags[:5]:  # Limit to 5 hashtags
                    if isinstance(tag, dict):
                        hashtags_list.append({
                            "id": tag.get("id") or tag.get("name", ""),
                            "name": tag.get("title") or tag.get("name", ""),
                            "title": tag.get("title") or tag.get("name", ""),
                            "desc": tag.get("desc", ""),
                            "stats": {"videoCount": 0, "viewCount": 0}
                        })

            # Music info
            music_meta = item.get("music") or item.get("musicMeta") or {}
            music_info = None
            if music_meta:
                music_info = {
                    "id": str(music_meta.get("id", "")),
                    "title": music_meta.get("title") or music_meta.get("name", "Original Sound"),
                    "authorName": music_meta.get("authorName") or music_meta.get("author", username),
                    "original": music_meta.get("original", False),
                    "playUrl": music_meta.get("playUrl", "")
                }

            # Video duration
            duration = v_meta.get("duration") or item.get("duration") or 15000  # default 15 seconds

            # Author info
            author_info = {
                "id": str(author_meta.get("id", "")),
                "uniqueId": username,
                "nickname": author_meta.get("nickname") or author_meta.get("name") or username,
                "avatar": author_meta.get("avatarThumb") or author_meta.get("avatar", ""),
                "followerCount": author_meta.get("fans") or author_meta.get("followers", 0),
                "followingCount": author_meta.get("following", 0),
                "heartCount": author_meta.get("heart", 0),
                "videoCount": author_meta.get("video") or author_meta.get("videos", 0),
                "verified": author_meta.get("verified", False)
            }

            live_results.append({
                "id": str(item.get("id", "")),
                "title": description,
                "description": description,
                "url": video_url,
                "cover_url": cover_url,
                "author_username": username,
                "play_addr": play_addr,  # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ
                "author": author_info,
                "stats": {
                    "playCount": int(play_count),
                    "diggCount": int(digg_count),
                    "commentCount": int(comment_count),
                    "shareCount": int(share_count)
                },
                "video": {
                    "duration": int(duration),
                    "ratio": "9:16",
                    "cover": cover_url,
                    "playAddr": play_addr,
                    "downloadAddr": play_addr
                },
                "music": music_info,
                "hashtags": hashtags_list,
                "createdAt": item.get("createTime") or item.get("createTimeISO", ""),
                "uts_score": 0,  # Will be calculated later if needed
                "viralScore": 0,
                "engagementRate": round((int(digg_count) + int(comment_count) + int(share_count)) / max(int(play_count), 1) * 100, 2) if play_count > 0 else 0
            })

        if len(live_results) > 0:
            print(f"‚úÖ Parsed {len(live_results)} items. First cover_url: {live_results[0]['cover_url'][:50] if live_results[0]['cover_url'] else 'EMPTY'}")

        return {"status": "ok", "items": live_results}

    # --- ‚úÖ –†–ï–ñ–ò–ú 2: DEEP SCAN (–ò–°–ü–û–õ–¨–ó–£–ï–ú –í–†–ï–ú–ï–ù–ù–´–ô –ë–£–§–ï–† –ë–î) ---
    scorer = TrendScorer()
    processed_trends_objects = [] 
    cascade_total = len(clean_items)

    for item in clean_items:
        p_id = str(item.get("id"))
        video_url = item.get("postPage") or item.get("url") or item.get("webVideoUrl")
        views_now = int(item.get("views") or (item.get("stats") or {}).get("playCount") or 0)
        current_stats = {"playCount": views_now}

        existing_video = db.query(Trend).filter(or_(Trend.platform_id == p_id, Trend.url == video_url)).first()

        try:
            if existing_video:
                # ‚úÖ –°–±—Ä–æ—Å –¢–æ—á–∫–∏ –ê –ø—Ä–∏ –Ω–æ–≤–æ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ (—Ö—Ä–∞–Ω–∏–º –≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è —Å–≤–µ—Ä–∫–∏)
                existing_video.initial_stats = current_stats 
                existing_video.stats = current_stats
                existing_video.last_scanned_at = None # –û–±–Ω—É–ª—è–µ–º, —á—Ç–æ–±—ã —Ä–µ—Å–∫–∞–Ω –ø–æ—Å—Ç–∞–≤–∏–ª –Ω–æ–≤—É—é –º–µ—Ç–∫—É
                db.add(existing_video)
                processed_trends_objects.append(existing_video)
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å ¬´–±—É—Ñ–µ—Ä–∞¬ª
                new_trend = Trend(
                    platform_id=p_id, url=video_url, 
                    cover_url=(item.get("video", {}).get("coverUrl") or "").replace(".heic", ".jpeg"),
                    description=item.get("title") or "No desc",
                    stats=current_stats, initial_stats=current_stats,
                    author_username=(item.get("channel") or {}).get("username") or "unknown",
                    uts_score=0, vertical=search_targets[0] or "deep_scan",
                    last_scanned_at=None
                )
                db.add(new_trend)
                processed_trends_objects.append(new_trend)
            db.commit()
        except: db.rollback()

    # 3. –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø (–¢–æ–ª—å–∫–æ –¥–ª—è Deep Scan)
    if req.is_deep and processed_trends_objects:
        processed_trends_objects = cluster_trends_by_visuals(processed_trends_objects)
        for t in processed_trends_objects: db.add(t)
        try: db.commit()
        except: db.rollback()

    # 4. –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –°–í–ï–†–ö–ò (2 –ú–ò–ù–£–¢–´ –¢–ï–°–¢)
    if req.is_deep and processed_trends_objects:
        saved_urls = [t.url for t in processed_trends_objects if t.url]
        if saved_urls:
            run_date = datetime.now() + timedelta(minutes=2) 
            scheduler.add_job(
                rescan_videos_task, 'date', run_date=run_date, 
                args=[saved_urls, f"batch_{int(time.time())}"]
            )
            print(f"‚è±Ô∏è –ó–ê–î–ê–ß–ê –°–í–ï–†–ö–ò –û–¢–ü–†–ê–í–õ–ï–ù–ê: –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 2 –º–∏–Ω—É—Ç—ã.")

    return {"status": "ok", "items": [trend_to_dict(t) for t in processed_trends_objects]}